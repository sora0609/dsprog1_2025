{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b46f9b",
   "metadata": {},
   "source": [
    "# 最終課題"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140d8a0b",
   "metadata": {},
   "source": [
    "### 課題のGithubリポジトリURLを提出してください\n",
    "### 武蔵野大学Webサイトのトップページにアクセス\n",
    "### 同一ドメインの全てのリンク（コメントアウトされていないもの）を辿り，全ページのURLと<title>を辞書型変数に格納する\n",
    "\n",
    "\n",
    "\n",
    "### key：URL\n",
    "### value：<title></title>で挟まれた文字列\n",
    "\n",
    "\n",
    "### 辞書型変数を print() で表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0169ac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webスクレイピングに最低限必要なライブラリをインポート\n",
    "from urllib import response\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from urllib.parse import urljoin, urlparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26804bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期設定\n",
    "URL = \"https://www.musashino-u.ac.jp/\" # アクセスするURL\n",
    "time.sleep = 1 # クローリングの際の負荷を削減するための待ち時間\n",
    "DOMAIN = urlparse(URL).netloc # 対象とするドメイン\n",
    "UNTARGET_URL = (\n",
    "    '.pdf', '.png', '.jpg', '.jpeg', '.gif', '.zip', \n",
    "    '.doc', '.docx', '.xls', '.xlsx', '.ppt', '.pptx', \n",
    "    '.mp4', '.mp3', '.css', '.js', '.ico','.webp'\n",
    ") # 今回の課題で対象外とする拡張子\n",
    "\n",
    "unvisit = [URL] # 訪問予定のURLを格納するリスト\n",
    "visited = set() # 訪問済みのURLを格納するセット\n",
    "sitemap = {} # 出力結果を格納する辞書"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a1c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl(start_url, sleep_time):\n",
    "    \n",
    "    print(\"クローリングスタート\\n\")\n",
    "\n",
    "    while unvisit:\n",
    "        current_url = unvisit.pop(0)\n",
    "\n",
    "        if current_url in visited: # すでに訪問済みかをチェック\n",
    "            continue\n",
    "\n",
    "        print(f\"訪問中: {current_url}\")\n",
    "        \n",
    "\n",
    "        time.sleeping(time.sleep) # 負荷削減のための待ち時間\n",
    "\n",
    "\n",
    "        try:\n",
    "            res = requests.get(current_url) # ぺージにアクセス\n",
    "            res.encoding = res.apparent_encoding\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  -> エラーが発生しました: {e}\") # エラーが発生した場合はスキップ\n",
    "            continue\n",
    "        visited.add(current_url) # 訪問済みリストに追加\n",
    "        \n",
    "        # ページ取得できた場合の処理\n",
    "        response.encoding = 'utf-8'\n",
    "        soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "        # タイトルを取得し、辞書に格納\n",
    "        title_tag = soup.find('title')\n",
    "        page_title = title_tag.text.strip() if title_tag else \"タイトルなし\"\n",
    "        sitemap[current_url] = page_title\n",
    "        \n",
    "        print(f\"tittle: {page_title}\")\n",
    "\n",
    "        # リンクページ内全てのリンクを辿る\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            href = link.get('href')\n",
    "            absolute_url = urljoin(current_url, href)\n",
    "            \n",
    "            parsed_url = urlparse(absolute_url)\n",
    "            cleaned_url = parsed_url.scheme + \"://\" + parsed_url.netloc + parsed_url.path # URLを正規化して作成\n",
    "\n",
    "        # リンク先のドメインをチェック\n",
    "            link_domain = urlparse(cleaned_url).netloc\n",
    "            \n",
    "        # 同一ドメインで未訪問のURLの場合はリストに追加\n",
    "        if parsed_url.netloc == DOMAIN and cleaned_url not in visited and cleaned_url not in unvisit:\n",
    "                if not any(cleaned_url.endswith(ext) for ext in UNTARGET_URL):\n",
    "                    unvisit.append(cleaned_url)\n",
    "                \n",
    "                return sitemap\n",
    "\n",
    "\n",
    "# 実行\n",
    "sitemap = crawl(URL, time.sleep)\n",
    "\n",
    "print(\"サイトマップ抽出結果:\\n\")\n",
    "print(sitemap)\n",
    "print(f\"合計抽出ページ数: {len(sitemap)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
